{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ycU4_3KSDqlb4SfbdCC64HEOBTkDPsM5",
      "authorship_tag": "ABX9TyMHFY+2Rr9iZiiLr8/J9/0T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John1495/BBC-NYOK/blob/main/Linear_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category-encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nlkhlmg-2TFx",
        "outputId": "f19c1962-fe08-467e-bcc7-f0e4abbb8f92"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category-encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (1.14.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category-encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category-encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category-encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category-encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category-encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category-encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression with Custom Interaction Features\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from category_encoders import TargetEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ===============================\n",
        "# 1. Load Data\n",
        "# ===============================\n",
        "import dask.dataframe as dd\n",
        "\n",
        "df = dd.read_csv(\"/kaggle/train.csv\", dtype={\n",
        "    'Podcast_Name': 'category',\n",
        "    'Episode_Title': 'category',\n",
        "    'Genre': 'category',\n",
        "    'Publication_Day': 'category',\n",
        "    'Publication_Time': 'category',\n",
        "    'Episode_Sentiment': 'category'\n",
        "}).compute()\n",
        "\n",
        "# ===============================\n",
        "# 2. Basic Cleaning\n",
        "# ===============================\n",
        "numerical_features = ['Episode_Length_minutes', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
        "categorical_features = ['Podcast_Name', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']\n",
        "\n",
        "# Drop unused columns\n",
        "df.drop(['id', 'Episode_Title'], axis=1, inplace=True)\n",
        "\n",
        "# Impute missing values\n",
        "numerical_imputer = SimpleImputer(strategy=\"median\")\n",
        "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "df[numerical_features] = numerical_imputer.fit_transform(df[numerical_features])\n",
        "df[categorical_features] = categorical_imputer.fit_transform(df[categorical_features])\n",
        "\n",
        "# ===============================\n",
        "# 3. Train/Test Split\n",
        "# ===============================\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# ===============================\n",
        "# 4. Feature Engineering\n",
        "# ===============================\n",
        "# Aggregated features from training data\n",
        "def create_aggregates(df, base_df):\n",
        "    podcast_features = base_df.groupby(\"Podcast_Name\").agg(\n",
        "        avg_podcast_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "        median_podcast_listening_time=('Listening_Time_minutes', 'median'),\n",
        "        total_podcast_listens=('Listening_Time_minutes', 'count')\n",
        "    ).reset_index()\n",
        "\n",
        "    genre_features = base_df.groupby(\"Genre\").agg(\n",
        "        avg_genre_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "        avg_genre_episode_length=('Episode_Length_minutes', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    df = df.merge(podcast_features, on=\"Podcast_Name\", how=\"left\")\n",
        "    df = df.merge(genre_features, on=\"Genre\", how=\"left\")\n",
        "\n",
        "    for col in ['avg_podcast_listening_time', 'median_podcast_listening_time', 'total_podcast_listens',\n",
        "                'avg_genre_listening_time', 'avg_genre_episode_length']:\n",
        "        df[col].fillna(base_df['Listening_Time_minutes'].mean(), inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = create_aggregates(train_df, train_df)\n",
        "test_df = create_aggregates(test_df, train_df)\n",
        "\n",
        "# ===============================\n",
        "# 5. Target Encoding\n",
        "# ===============================\n",
        "target_encoder = TargetEncoder(cols=['Podcast_Name'])\n",
        "train_df['Podcast_Name'] = target_encoder.fit_transform(train_df['Podcast_Name'], train_df['Listening_Time_minutes'])\n",
        "test_df['Podcast_Name'] = target_encoder.transform(test_df['Podcast_Name'])\n",
        "\n",
        "# ===============================\n",
        "# 6. Custom Interaction Features\n",
        "# ===============================\n",
        "def create_interactions(df):\n",
        "    df['Length_x_Ads'] = df['Episode_Length_minutes'] * df['Number_of_Ads']\n",
        "    df['Guest_x_GenreTime'] = df['Guest_Popularity_percentage'] * df['avg_genre_listening_time']\n",
        "    df['Podcast_x_AvgTime'] = df['Podcast_Name'] * df['avg_podcast_listening_time']\n",
        "    return df\n",
        "\n",
        "train_df = create_interactions(train_df)\n",
        "test_df = create_interactions(test_df)\n",
        "\n",
        "# ===============================\n",
        "# 7. Final Feature List\n",
        "# ===============================\n",
        "numeric_features = [\n",
        "    'Episode_Length_minutes', 'Guest_Popularity_percentage', 'Number_of_Ads',\n",
        "    'Podcast_Name', 'avg_podcast_listening_time', 'median_podcast_listening_time',\n",
        "    'total_podcast_listens', 'avg_genre_listening_time', 'avg_genre_episode_length',\n",
        "    'Length_x_Ads', 'Guest_x_GenreTime', 'Podcast_x_AvgTime'\n",
        "]\n",
        "one_hot_features = ['Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']\n",
        "\n",
        "X_train = train_df[numeric_features + one_hot_features]\n",
        "y_train = train_df['Listening_Time_minutes']\n",
        "X_test = test_df[numeric_features + one_hot_features]\n",
        "y_test = test_df['Listening_Time_minutes']\n",
        "\n",
        "# ===============================\n",
        "# 8. Preprocessing Pipeline\n",
        "# ===============================\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_pipeline, numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), one_hot_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 9. Linear Regression Pipeline\n",
        "# ===============================\n",
        "model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ===============================\n",
        "# 10. Evaluation\n",
        "# ===============================\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"üìâ Final Test RMSE with Custom Interaction Features: {rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNJM9mJ06kjR",
        "outputId": "ee1b207a-d6c7-4dde-8a65-681bbdf6667c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìâ Final Test RMSE with Custom Interaction Features: 13.37\n"
          ]
        }
      ]
    }
  ]
}