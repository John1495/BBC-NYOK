{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John1495/BBC-NYOK/blob/main/Copy_of_Linear_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load your trained model\n",
        "model_path = '/content/drive/MyDrive/TESTING/rf_model.joblib'\n",
        "rf_model = joblib.load(model_path)\n",
        "\n",
        "# Load your datasets (replace paths with your actual paths)\n",
        "train_df = pd.read_csv('/kaggle/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/test.csv')"
      ],
      "metadata": {
        "id": "83nY3CpWlnN2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df, is_train=True):\n",
        "    \"\"\"Clean the dataset with appropriate handling for train vs test\"\"\"\n",
        "\n",
        "    # 1. Handle missing values\n",
        "    numerical_features = ['Episode_Length_minutes', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
        "    categorical_features = ['Podcast_Name', 'Episode_Title', 'Genre', 'Publication_Day',\n",
        "                          'Publication_Time', 'Episode_Sentiment']\n",
        "\n",
        "    if is_train:\n",
        "        # For training data - fit imputers\n",
        "        df[numerical_features] = df[numerical_features].fillna(df[numerical_features].median())\n",
        "        df[categorical_features] = df[categorical_features].fillna(df[categorical_features].mode().iloc[0])\n",
        "\n",
        "        # Save imputation values for test data\n",
        "        global train_medians, train_modes\n",
        "        train_medians = df[numerical_features].median()\n",
        "        train_modes = df[categorical_features].mode().iloc[0]\n",
        "    else:\n",
        "        # For test data - use training imputation values\n",
        "        df[numerical_features] = df[numerical_features].fillna(train_medians)\n",
        "        df[categorical_features] = df[categorical_features].fillna(train_modes)\n",
        "\n",
        "    # 2. Convert Publication_Day to datetime\n",
        "    def get_date_from_weekday(weekday_str):\n",
        "        weekday_mapping = {\n",
        "            'Monday': 0, 'Tuesday': 1, 'Wednesday': 2,\n",
        "            'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6\n",
        "        }\n",
        "        start_date = datetime(2023, 1, 1)  # Same as training\n",
        "        try:\n",
        "            target_weekday = weekday_mapping[weekday_str]\n",
        "            delta_days = (target_weekday - start_date.weekday()) % 7\n",
        "            return start_date + timedelta(days=delta_days)\n",
        "        except KeyError:\n",
        "            return pd.NaT\n",
        "\n",
        "    df['Publication_Day'] = df['Publication_Day'].apply(get_date_from_weekday)\n",
        "    df['Publication_Day'] = pd.to_datetime(df['Publication_Day'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Clean training data\n",
        "train_df = clean_data(train_df, is_train=True)\n",
        "\n",
        "# Clean test data (using training imputation values)\n",
        "test_df = clean_data(test_df, is_train=False)"
      ],
      "metadata": {
        "id": "8NLHY5qBmXhj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def engineer_features(df, is_train=True):\n",
        "    \"\"\"Add all engineered features\"\"\"\n",
        "\n",
        "    # 1. Aggregated features\n",
        "    if is_train:\n",
        "        # Calculate aggregations from training data\n",
        "        global podcast_features, genre_features, sentiment_features, day_features\n",
        "        podcast_features = df.groupby(\"Podcast_Name\").agg(\n",
        "            avg_podcast_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "            median_podcast_listening_time=('Listening_Time_minutes', 'median'),\n",
        "            total_podcast_listens=('Listening_Time_minutes', 'count'),\n",
        "            std_podcast_listening_time=('Listening_Time_minutes', 'std'),\n",
        "            avg_episode_length=('Episode_Length_minutes', 'mean'),\n",
        "            avg_host_popularity=('Host_Popularity_percentage', 'mean'),\n",
        "            avg_guest_popularity=('Guest_Popularity_percentage', 'mean'),\n",
        "            avg_num_ads=('Number_of_Ads', 'mean')\n",
        "        ).reset_index()\n",
        "\n",
        "        genre_features = df.groupby(\"Genre\").agg(\n",
        "            avg_genre_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "            avg_genre_episode_length=('Episode_Length_minutes', 'mean'),\n",
        "            total_genre_listens=('Listening_Time_minutes', 'count')\n",
        "        ).reset_index()\n",
        "\n",
        "        sentiment_features = df.groupby(\"Episode_Sentiment\").agg(\n",
        "            avg_sentiment_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "            total_sentiment_listens=('Listening_Time_minutes', 'count')\n",
        "        ).reset_index()\n",
        "\n",
        "        day_features = df.groupby(\"Publication_Day\").agg(\n",
        "            avg_day_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "            total_day_listens=('Listening_Time_minutes', 'count')\n",
        "        ).reset_index()\n",
        "\n",
        "    # Merge features (for both train and test)\n",
        "    df = df.merge(podcast_features, on=\"Podcast_Name\", how=\"left\")\n",
        "    df = df.merge(genre_features, on=\"Genre\", how=\"left\")\n",
        "    df = df.merge(sentiment_features, on=\"Episode_Sentiment\", how=\"left\")\n",
        "    df = df.merge(day_features, on=\"Publication_Day\", how=\"left\")\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    # 2. Time-based features\n",
        "    df = df.sort_values('Publication_Day')\n",
        "    min_date = train_df['Publication_Day'].min()  # Always use training min date\n",
        "    df['Days_Since_Start'] = (df['Publication_Day'] - min_date).dt.days\n",
        "\n",
        "    # Lag features (only for training)\n",
        "    if is_train:\n",
        "        df['Lag_1_Listening'] = df['Listening_Time_minutes'].shift(1)\n",
        "        df['Lag_1_Podcast'] = df.groupby('Podcast_Name')['Listening_Time_minutes'].shift(1)\n",
        "\n",
        "    # Rolling features (only for training)\n",
        "    if is_train:\n",
        "        df['Rolling_3'] = df['Listening_Time_minutes'].rolling(window=3).mean()\n",
        "        df['Rolling_3_Podcast'] = df.groupby('Podcast_Name')['Listening_Time_minutes'].transform(\n",
        "            lambda x: x.rolling(window=3).mean())\n",
        "\n",
        "    # Weekday features\n",
        "    df['Weekday'] = df['Publication_Day'].dt.weekday\n",
        "    df = pd.get_dummies(df, columns=['Weekday'], prefix='Day')\n",
        "\n",
        "    # Day of year seasonality\n",
        "    df['Day_Sin'] = np.sin(2 * np.pi * df['Publication_Day'].dt.dayofyear / 365)\n",
        "    df['Day_Cos'] = np.cos(2 * np.pi * df['Publication_Day'].dt.dayofyear / 365)\n",
        "\n",
        "    # Fill any remaining NaNs\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Engineer features for both datasets\n",
        "train_df = engineer_features(train_df, is_train=True)\n",
        "test_df = engineer_features(test_df, is_train=False)"
      ],
      "metadata": {
        "id": "VzBYLFB6mcFl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_for_modeling(df, is_train=True):\n",
        "    \"\"\"Prepare data for modeling/prediction\"\"\"\n",
        "\n",
        "    # Drop non-feature columns\n",
        "    df_model = df.drop(['id', 'Episode_Title'], axis=1, errors='ignore')\n",
        "\n",
        "    # Encode categorical variables\n",
        "    if is_train:\n",
        "        global label_encoders\n",
        "        label_encoders = {}\n",
        "        for col in ['Podcast_Name', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']:\n",
        "            le = LabelEncoder()\n",
        "            df_model[col] = le.fit_transform(df_model[col])\n",
        "            label_encoders[col] = le\n",
        "    else:\n",
        "        # For test data - use training label encoders\n",
        "        for col in ['Podcast_Name', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']:\n",
        "            if col in df_model.columns:\n",
        "                le = label_encoders[col]\n",
        "                # Handle unseen categories by mapping to 'unknown'\n",
        "                unseen_mask = ~df_model[col].isin(le.classes_)\n",
        "                if unseen_mask.any():\n",
        "                    df_model.loc[unseen_mask, col] = le.classes_[0]  # default to first category\n",
        "                df_model[col] = le.transform(df_model[col])\n",
        "\n",
        "    # Ensure all expected columns are present\n",
        "    if not is_train:\n",
        "        # Add missing columns with 0 values\n",
        "        expected_columns = set(train_df.columns) - {'id', 'Episode_Title', 'Listening_Time_minutes'}\n",
        "        missing_cols = expected_columns - set(df_model.columns)\n",
        "        for col in missing_cols:\n",
        "            df_model[col] = 0\n",
        "\n",
        "        # Reorder columns to match training\n",
        "        df_model = df_model[list(expected_columns)]\n",
        "\n",
        "    return df_model\n",
        "\n",
        "# Prepare training data (if you want to retrain)\n",
        "X_train = prepare_for_modeling(train_df, is_train=True)\n",
        "y_train = train_df['Listening_Time_minutes']\n",
        "\n",
        "# Prepare test data\n",
        "X_test = prepare_for_modeling(test_df, is_train=False)"
      ],
      "metadata": {
        "id": "IYkVqfRomkAl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_for_modeling(df, is_train=True):\n",
        "    \"\"\"Prepare data for modeling/prediction with all required features\"\"\"\n",
        "\n",
        "    # Drop non-feature columns\n",
        "    df_model = df.drop(['id', 'Episode_Title'], axis=1, errors='ignore')\n",
        "\n",
        "    # Add missing diff features if they don't exist\n",
        "    if 'Listening_Diff' not in df_model.columns:\n",
        "        df_model['Listening_Diff'] = 0\n",
        "    if 'Podcast_Diff' not in df_model.columns:\n",
        "        df_model['Podcast_Diff'] = 0\n",
        "\n",
        "    # Encode categorical variables\n",
        "    if is_train:\n",
        "        global label_encoders\n",
        "        label_encoders = {}\n",
        "        for col in ['Podcast_Name', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']:\n",
        "            le = LabelEncoder()\n",
        "            df_model[col] = le.fit_transform(df_model[col])\n",
        "            label_encoders[col] = le\n",
        "    else:\n",
        "        # For test data - use training label encoders\n",
        "        for col in ['Podcast_Name', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']:\n",
        "            if col in df_model.columns:\n",
        "                le = label_encoders[col]\n",
        "                # Handle unseen categories\n",
        "                unseen_mask = ~df_model[col].isin(le.classes_)\n",
        "                if unseen_mask.any():\n",
        "                    df_model.loc[unseen_mask, col] = le.classes_[0]\n",
        "                df_model[col] = le.transform(df_model[col])\n",
        "\n",
        "    # Get the expected columns from the trained model\n",
        "    expected_columns = rf_model.feature_names_in_\n",
        "\n",
        "    # Add missing columns with 0 values\n",
        "    missing_cols = set(expected_columns) - set(df_model.columns)\n",
        "    for col in missing_cols:\n",
        "        df_model[col] = 0\n",
        "\n",
        "    # Remove extra columns not in training\n",
        "    extra_cols = set(df_model.columns) - set(expected_columns)\n",
        "    if extra_cols:\n",
        "        df_model = df_model.drop(columns=list(extra_cols))\n",
        "\n",
        "    # Ensure exact column order from training\n",
        "    df_model = df_model[list(expected_columns)]\n",
        "\n",
        "    return df_model\n",
        "\n",
        "# Re-prepare the test data with the fixed function\n",
        "X_test = prepare_for_modeling(test_df, is_train=False)\n",
        "\n",
        "# Now make predictions\n",
        "test_predictions = rf_model.predict(X_test)\n",
        "test_df['Predicted_Listening_Time'] = test_predictions\n",
        "\n",
        "# Show results\n",
        "print(\"Predictions made successfully!\")\n",
        "print(test_df[['Podcast_Name', 'Episode_Title', 'Predicted_Listening_Time']].head(100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMlKizMpE7az",
        "outputId": "455d9617-d423-48a2-d012-4c4ab8f510f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions made successfully!\n",
            "             Podcast_Name Episode_Title  Predicted_Listening_Time\n",
            "160512     Healthy Living   Episode 100                  0.518241\n",
            "112886      Wellness Wave    Episode 81                 31.540785\n",
            "240842        Funny Folks     Episode 3                 33.066673\n",
            "112888        Mind & Body    Episode 69                  6.647227\n",
            "208502    Fashion Forward    Episode 51                 44.435585\n",
            "...                   ...           ...                       ...\n",
            "27505     Mystery Matters     Episode 9                 27.897782\n",
            "73357   Business Insights    Episode 67                  9.276149\n",
            "197454       Learning Lab    Episode 58                 30.228786\n",
            "73358   Detective Diaries    Episode 40                 38.356808\n",
            "112799  Business Insights    Episode 72                 36.253707\n",
            "\n",
            "[100 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Prepare predictions output (without actual values)\n",
        "output_df = test_df[['id', 'Podcast_Name', 'Episode_Title', 'Genre',\n",
        "                    'Episode_Length_minutes', 'Predicted_Listening_Time']].copy()\n",
        "\n",
        "# Save path\n",
        "save_path = '/content/drive/My Drive/podcast_predictions.csv'\n",
        "\n",
        "# Save to CSV\n",
        "output_df.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"✅ Predictions saved to: {save_path}\")\n",
        "print(\"\\nSample of saved predictions:\")\n",
        "print(output_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCbRXjHoK2r_",
        "outputId": "b8733fda-c983-408b-90e7-d612aa280371"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Predictions saved to: /content/drive/My Drive/podcast_predictions.csv\n",
            "\n",
            "Sample of saved predictions:\n",
            "            id     Podcast_Name Episode_Title      Genre  \\\n",
            "160512  910512   Healthy Living   Episode 100     Health   \n",
            "112886  862886    Wellness Wave    Episode 81     Health   \n",
            "240842  990842      Funny Folks     Episode 3     Comedy   \n",
            "112888  862888      Mind & Body    Episode 69     Health   \n",
            "208502  958502  Fashion Forward    Episode 51  Lifestyle   \n",
            "\n",
            "        Episode_Length_minutes  Predicted_Listening_Time  \n",
            "160512                   13.04                  0.518241  \n",
            "112886                   53.76                 31.540785  \n",
            "240842                   44.66                 33.066673  \n",
            "112888                   26.94                  6.647227  \n",
            "208502                  106.09                 44.435585  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if file exists\n",
        "import os\n",
        "if os.path.exists(save_path):\n",
        "    print(\"\\nVerification:\")\n",
        "    print(f\"File size: {os.path.getsize(save_path)/1024:.1f} KB\")\n",
        "    print(f\"Created at: {pd.to_datetime(os.path.getctime(save_path), unit='s')}\")\n",
        "\n",
        "    # Show first few lines\n",
        "    print(\"\\nFile preview:\")\n",
        "    !head \"{save_path}\"\n",
        "else:\n",
        "    print(\"⚠️ Error: File not saved successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAmzBgdgLW-B",
        "outputId": "0da1d8eb-49f2-4d73-a8a8-6eb3f298a079"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verification:\n",
            "File size: 15526.3 KB\n",
            "Created at: 2025-04-16 15:15:43\n",
            "\n",
            "File preview:\n",
            "id,Podcast_Name,Episode_Title,Genre,Episode_Length_minutes,Predicted_Listening_Time\n",
            "910512,Healthy Living,Episode 100,Health,13.04,0.5182407999999998\n",
            "862886,Wellness Wave,Episode 81,Health,53.76,31.540785300000024\n",
            "990842,Funny Folks,Episode 3,Comedy,44.66,33.066672700000005\n",
            "862888,Mind & Body,Episode 69,Health,26.94,6.647227199999998\n",
            "958502,Fashion Forward,Episode 51,Lifestyle,106.09,44.43558499999998\n",
            "823277,Study Sessions,Episode 90,Education,63.84,33.6878509\n",
            "796449,Style Guide,Episode 48,Lifestyle,10.27,0.3816811000000001\n",
            "910039,Finance Focus,Episode 92,Business,15.96,1.1290542\n",
            "823275,Game Day,Episode 32,Sports,52.99,31.845013800000014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example organized path\n",
        "save_path = '/content/drive/My Drive/DataScience/PodcastProject/predictions_2023.csv'"
      ],
      "metadata": {
        "id": "s19CzCRGLb4c"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_path = f'/content/drive/My Drive/podcast_predictions_{timestamp}.csv'"
      ],
      "metadata": {
        "id": "LDgWXhjdLgnt"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1K-tzGhCEhkM4aYiHjZ0MpEdd0-0ufJDl",
      "authorship_tag": "ABX9TyNZDK3oTfXjKuLVZ86/0lZe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}