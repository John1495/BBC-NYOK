{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John1495/BBC-NYOK/blob/main/Another_copy_of_podcast_prediction_pipeline_combinedtrain12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "112eeed3",
      "metadata": {
        "id": "112eeed3"
      },
      "source": [
        "# ðŸŽ§ Podcast Listening Time Prediction\n",
        "This notebook performs data preprocessing, exploratory data analysis (EDA), feature engineering, and model training to predict podcast listening time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23fd5366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23fd5366",
        "outputId": "818fa716-359c-4751-c289-a701eda12b20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Missing Values After Imputation:\n",
            "id                             0\n",
            "Podcast_Name                   0\n",
            "Episode_Title                  0\n",
            "Episode_Length_minutes         0\n",
            "Genre                          0\n",
            "Host_Popularity_percentage     0\n",
            "Publication_Day                0\n",
            "Publication_Time               0\n",
            "Guest_Popularity_percentage    0\n",
            "Number_of_Ads                  0\n",
            "Episode_Sentiment              0\n",
            "Listening_Time_minutes         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.impute import SimpleImputer\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data with optimized dtypes\n",
        "df = dd.read_csv(\"/kaggle/train.csv\", dtype={\n",
        "    'Podcast_Name': 'category',\n",
        "    'Episode_Title': 'category',\n",
        "    'Genre': 'category',\n",
        "    'Publication_Day': 'category',\n",
        "    'Publication_Time': 'category',\n",
        "    'Episode_Sentiment': 'category'\n",
        "}).compute()\n",
        "\n",
        "# Separate feature types\n",
        "numerical_features = ['Episode_Length_minutes', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
        "categorical_features = ['Podcast_Name', 'Episode_Title', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']\n",
        "\n",
        "# Impute missing values\n",
        "df[numerical_features] = SimpleImputer(strategy=\"median\").fit_transform(df[numerical_features])\n",
        "df[categorical_features] = SimpleImputer(strategy=\"most_frequent\").fit_transform(df[categorical_features])\n",
        "\n",
        "print(\"âœ… Missing Values After Imputation:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gYCvM0GMFUFU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYCvM0GMFUFU",
        "outputId": "8f4febb2-2e1d-45c9-e29c-8ce03000a251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22625b0c",
      "metadata": {
        "id": "22625b0c"
      },
      "source": [
        "## ðŸ§  Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60738925",
      "metadata": {
        "id": "60738925"
      },
      "outputs": [],
      "source": [
        "# Aggregations\n",
        "podcast_features = df.groupby(\"Podcast_Name\").agg(\n",
        "    avg_podcast_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "    median_podcast_listening_time=('Listening_Time_minutes', 'median'),\n",
        "    total_podcast_listens=('Listening_Time_minutes', 'count'),\n",
        "    std_podcast_listening_time=('Listening_Time_minutes', 'std'),\n",
        "    avg_episode_length=('Episode_Length_minutes', 'mean'),\n",
        "    avg_host_popularity=('Host_Popularity_percentage', 'mean'),\n",
        "    avg_guest_popularity=('Guest_Popularity_percentage', 'mean'),\n",
        "    avg_num_ads=('Number_of_Ads', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "genre_features = df.groupby(\"Genre\").agg(\n",
        "    avg_genre_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "    avg_genre_episode_length=('Episode_Length_minutes', 'mean'),\n",
        "    total_genre_listens=('Listening_Time_minutes', 'count')\n",
        ").reset_index()\n",
        "\n",
        "sentiment_features = df.groupby(\"Episode_Sentiment\").agg(\n",
        "    avg_sentiment_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "    total_sentiment_listens=('Listening_Time_minutes', 'count')\n",
        ").reset_index()\n",
        "\n",
        "day_features = df.groupby(\"Publication_Day\").agg(\n",
        "    avg_day_listening_time=('Listening_Time_minutes', 'mean'),\n",
        "    total_day_listens=('Listening_Time_minutes', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# Merge engineered features\n",
        "df = df.merge(podcast_features, on=\"Podcast_Name\", how=\"left\")\n",
        "df = df.merge(genre_features, on=\"Genre\", how=\"left\")\n",
        "df = df.merge(sentiment_features, on=\"Episode_Sentiment\", how=\"left\")\n",
        "df = df.merge(day_features, on=\"Publication_Day\", how=\"left\")\n",
        "df.fillna(0, inplace=True)  # Handle any remaining NaNs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j5XJggnoIqI5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5XJggnoIqI5",
        "outputId": "91e7001b-23be-407a-95da-f1fa8e29f414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0   2025-04-03\n",
            "1   2025-04-05\n",
            "2   2025-04-01\n",
            "3   2025-03-31\n",
            "4   2025-03-31\n",
            "Name: Publication_Day, dtype: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "# Mapping weekday names to dates\n",
        "def get_date_from_weekday(weekday):\n",
        "    # Weekday names as they appear in df: 'Monday', 'Tuesday', etc.\n",
        "    weekday_mapping = {\n",
        "        'Monday': 0,\n",
        "        'Tuesday': 1,\n",
        "        'Wednesday': 2,\n",
        "        'Thursday': 3,\n",
        "        'Friday': 4,\n",
        "        'Saturday': 5,\n",
        "        'Sunday': 6\n",
        "    }\n",
        "    # Get the weekday number from the dictionary\n",
        "    weekday_number = weekday_mapping[weekday]\n",
        "\n",
        "    # Calculate the date difference from the start date\n",
        "    delta_days = weekday_number - start_date.weekday()\n",
        "    date_of_weekday = start_date + timedelta(days=delta_days)\n",
        "\n",
        "    return date_of_weekday.strftime('%Y-%m-%d')  # Return date as a string\n",
        "\n",
        "# Applying the conversion function to Publication_Day column\n",
        "df['Publication_Day'] = df['Publication_Day'].apply(get_date_from_weekday)\n",
        "\n",
        "# Now parse the date correctly\n",
        "df['Publication_Day'] = pd.to_datetime(df['Publication_Day'])\n",
        "\n",
        "# Check if the conversion is successful\n",
        "print(df['Publication_Day'].head()) '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "muEqhC6GIUem",
      "metadata": {
        "id": "muEqhC6GIUem"
      },
      "outputs": [],
      "source": [
        "# --- Ordinal Time Features ---\n",
        "df = df.sort_values('Publication_Day')\n",
        "\n",
        "# ðŸ’¡ Days since start\n",
        "df['Days_Since_Start'] = (df['Publication_Day'] - df['Publication_Day'].min()).dt.days\n",
        "\n",
        "# ðŸ’¡ Lag features\n",
        "df['Lag_1_Listening'] = df['Listening_Time_minutes'].shift(1)\n",
        "df['Lag_1_Podcast'] = df.groupby('Podcast_Name')['Listening_Time_minutes'].shift(1)\n",
        "\n",
        "# ðŸ’¡ Diff features\n",
        "df['Listening_Diff'] = df['Listening_Time_minutes'].diff()\n",
        "df['Podcast_Diff'] = df.groupby('Podcast_Name')['Listening_Time_minutes'].diff()\n",
        "\n",
        "# ðŸ’¡ Rolling features (3-day trend)\n",
        "df['Rolling_3'] = df['Listening_Time_minutes'].rolling(window=3).mean()\n",
        "df['Rolling_3_Podcast'] = df.groupby('Podcast_Name')['Listening_Time_minutes'].transform(lambda x: x.rolling(window=3).mean())\n",
        "\n",
        "# ðŸ’¡ Seasonality: Weekday\n",
        "df['Weekday'] = df['Publication_Day'].dt.weekday\n",
        "df = pd.get_dummies(df, columns=['Weekday'], prefix='Day')\n",
        "\n",
        "# ðŸ’¡ Optional: sine/cosine transformation for day-of-year seasonality\n",
        "df['Day_Sin'] = np.sin(2 * np.pi * df['Publication_Day'].dt.dayofyear / 365)\n",
        "df['Day_Cos'] = np.cos(2 * np.pi * df['Publication_Day'].dt.dayofyear / 365)\n",
        "\n",
        "# --- Final clean-up ---\n",
        "df.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae9ce2bf",
      "metadata": {
        "id": "ae9ce2bf"
      },
      "source": [
        "## ðŸ¤– Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a74c3207",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a74c3207",
        "outputId": "e16bddcb-b63a-4322-fef5-d092843fbc93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest RMSE: 0.45\n"
          ]
        }
      ],
      "source": [
        "#Prepare data\n",
        "df_model = df.copy()\n",
        "df_model.drop(['id', 'Episode_Title'], axis=1, inplace=True)  # Dropping non-relevant columns\n",
        "\n",
        "# Encode categorical variables\n",
        "for col in ['Podcast_Name', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']:\n",
        "    df_model[col] = LabelEncoder().fit_transform(df_model[col])\n",
        "\n",
        "# Define features and target variable\n",
        "X = df_model.drop('Listening_Time_minutes', axis=1)\n",
        "y = df_model['Listening_Time_minutes']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "preds = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "\n",
        "# Output the RMSE\n",
        "print(f\"Random Forest RMSE: {rmse:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FeyyR_GuqQTM",
      "metadata": {
        "id": "FeyyR_GuqQTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2778835-a368-4bbb-cb94-55b493b17c2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['random_forest_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        " # Save the trained model\n",
        "joblib.dump(rf_model, 'random_forest_model.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}